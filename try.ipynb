{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uio2.model import UnifiedIOModel\n",
    "\n",
    "model = UnifiedIOModel.from_pretrained(\"allenai/uio2-XL\").to(\"cuda\")\n",
    "# This loads the large (1B) model, load the XL (3B) or XXL (7B) with allenai/uio2-xl and allenai/uio2-xxl``\n",
    "# XXL太大啦 光模型就27G cpu内存爆了\n",
    "# XL 12.7个G 勉强吧 经常崩溃掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import PreTrainedTokenizerFast\n",
    "# import torch\n",
    "\n",
    "# tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
    "#     \"allenai/Llama-3.1-Tulu-3-8B\",  # \"meta-llama/Llama-3.2-1B\" 好像闭源了, 我申请他不给我通过\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uio2.preprocessing import UnifiedIOPreprocessor\n",
    "\n",
    "# model file在 https://huggingface.co/allenai/tulu-v1-llama2-7b/tree/main 下载的\n",
    "preprocessor = UnifiedIOPreprocessor.from_pretrained(\n",
    "    \"allenai/uio2-preprocessor\",\n",
    "    # tokenizer=tokenizer,\n",
    "    tokenizer=\"./tokenizer.model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.set_modalities(input_modalities=[\"text\"], target_modalities=[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uio2.runner import TaskRunner\n",
    "\n",
    "runner = TaskRunner(model, preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = runner.image_generation(\"A photo of a girl holding a umbrella\")\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./000000009448.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = runner.image_captioning(img_path)\n",
    "# prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = runner.vqa(img_path, \"what color is umbrella?\")\n",
    "# prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_img = runner.surface_normal_estimation(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"demo.jpg\", surface_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_img = runner.depth_estimation(img_path)\n",
    "# depth_img\n",
    "cv2.imwrite(\"demo.jpg\", depth_img * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_img = runner.depth_estimation(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = runner.refexp(img_path, \"girl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_path)\n",
    "box = [int(x) for x in box]\n",
    "cv2.rectangle(img, (box[0], box[1], box[2], box[3]), (0, 255, 0), 2)\n",
    "cv2.imwrite(\"demo.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoint = runner.keypoint(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 画点\n",
    "img = cv2.imread(img_path)\n",
    "for i in range(keypoint[0].shape[0]):\n",
    "    cv2.circle(\n",
    "        img, (int(keypoint[0][i][0]), int(keypoint[0][i][1])), 3, (0, 255, 0), -1\n",
    "    )\n",
    "cv2.imwrite(\"demo.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = runner.vqa(None, \"one plus one equals?\")\n",
    "ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "untorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
